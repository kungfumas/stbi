{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"User-based collaborative filtering. This technique uses other users to recommend items to the input user. It attempts to find users that have similar preferences and opinions as the input and then recommends items that they have liked to the input. <br>\n\nI am going to use simple method here based on the Pearson Correlation using pandas. It's a simple approach and it doesn't cover many topics, but it good for get acquainted with recommender systems. <br>\n\nP.S. In this notebook I use updated version of dataset from [ here ](https://github.com/zygmuntz/goodbooks-10k)","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-09-14T05:28:11.308887Z","iopub.execute_input":"2021-09-14T05:28:11.30927Z","iopub.status.idle":"2021-09-14T05:28:11.314948Z","shell.execute_reply.started":"2021-09-14T05:28:11.309236Z","shell.execute_reply":"2021-09-14T05:28:11.313733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"books_df = pd.read_csv('https://raw.githubusercontent.com/kungfumas/stbi/master/books.csv')\nratings_df = pd.read_csv('https://raw.githubusercontent.com/kungfumas/stbi/master/bookratings.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-14T05:28:18.457869Z","iopub.execute_input":"2021-09-14T05:28:18.458597Z","iopub.status.idle":"2021-09-14T05:28:38.548307Z","shell.execute_reply.started":"2021-09-14T05:28:18.458532Z","shell.execute_reply":"2021-09-14T05:28:38.545695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"books_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"books_df.info()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"books_df.sample(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ratings_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ratings_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ratings_df.sample(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As a fan of literature I prepared my own list of some my favourite books (you can also use any user from dataset): \n\n   - Jack London _\"Martin Eden\"_ <br>\n   - Franz Kafka _\"The trial\"_ <br>\n   - Stephen King _\"Pet Sematary\"_ <br>\n   - Gabriel Garcia Markes _\"One Hundred Years of Solitude\"_ <br>\n   - Charles Bukowski _\"Ham on Rye\"_ <br>\n   - John Steinbeck _\"The Grapes of Wrath\"_ <br>\n   - Kurt Vonnegut _\"Cat's Cradle\"_ <br>\n   - Fedor Dostoyevsky _\"Crime and Punishment\"_ <br>\n\nAnd below I rated these books.","metadata":{}},{"cell_type":"code","source":"my_list = {'Martin Eden': 5,\n            'Pet Sematary': 5,\n            'One Hundred Years of Solitude': 5,\n            'Ham on Rye': 5,\n            'The Grapes of Wrath': 4, \n            \"Cat's Cradle\": 5,\n            'Crime and Punishment': 4,\n            'The Trial': 4}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create dataframe for new user (me)\nuser_books = pd.DataFrame(columns=['title', 'rating'], data=my_list.items())\nuser_books","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Add book_id from books_df\nnew_user = pd.merge(user_books, books_df, on='title', how='inner')\nnew_user = new_user[['book_id', 'title', 'rating']].sort_values(by='book_id')\nnew_user","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Select a users with books I have read.","metadata":{}},{"cell_type":"code","source":"other_users = ratings_df[ratings_df['book_id'].isin(new_user['book_id'].values)]\nother_users","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"other_users['user_id'].nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"18637 users had read at least one book from my list. ","metadata":{}},{"cell_type":"code","source":"# Sort users by count of most mutual books with me\nusers_mutual_books = other_users.groupby(['user_id'])\nusers_mutual_books = sorted(users_mutual_books, key=lambda x: len(x[1]), reverse=True)\nusers_mutual_books[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I will be using only first 100 records, these with the most common part of books","metadata":{}},{"cell_type":"code","source":"top_users = users_mutual_books[:100]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's calculate a similarity score for each user using Pearson correlation function and use these scores as weights later. ","metadata":{}},{"cell_type":"code","source":"# Pearson correlation\nfrom scipy.stats import pearsonr\n\npearson_corr = {}\n\nfor user_id, books in top_users:\n    # Books should be sorted\n    books = books.sort_values(by='book_id')\n    book_list = books['book_id'].values\n\n    new_user_ratings = new_user[new_user['book_id'].isin(book_list)]['rating'].values \n    user_ratings = books[books['book_id'].isin(book_list)]['rating'].values\n\n    corr = pearsonr(new_user_ratings, user_ratings)\n    pearson_corr[user_id] = corr[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get top50 users with the highest similarity indices\npearson_df = pd.DataFrame(columns=['user_id', 'similarity_index'], data=pearson_corr.items())\npearson_df = pearson_df.sort_values(by='similarity_index', ascending=False)[:50]\npearson_df","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get all books for these users and add weighted book's ratings\nusers_rating = pearson_df.merge(ratings_df, on='user_id', how='inner')\nusers_rating['weighted_rating'] = users_rating['rating'] * users_rating['similarity_index']\nusers_rating","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now it rests only calculate average recommendation score and select items with the highest score. <br>","metadata":{}},{"cell_type":"code","source":"# Calculate sum of similarity index and weighted rating for each book\ngrouped_ratings = users_rating.groupby('book_id').sum()[['similarity_index', 'weighted_rating']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recommend_books = pd.DataFrame()\n\n# Add average recommendation score\nrecommend_books['avg_reccomend_score'] = grouped_ratings['weighted_rating']/grouped_ratings['similarity_index']\nrecommend_books['book_id'] = grouped_ratings.index\nrecommend_books = recommend_books.reset_index(drop=True)\n\n# Left books with the highest score\nrecommend_books = recommend_books[(recommend_books['avg_reccomend_score'] == 5)]\nrecommend_books","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's have a look for list of 10 recommendation. ","metadata":{}},{"cell_type":"code","source":"# Let's see our recomendations\nrecommendation = books_df[books_df['book_id'].isin(recommend_books['book_id'])][['authors', 'title', 'book_id']].sample(10)\nrecommendation","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nUser object attributes:\n\n    user likes\n    user played(audio)\n    users liked audio(from other people)\n    users interacted tags\n    user lat\n    user lng\n    user replies\n\"\"\"\nimport pandas as pd\nimport numpy as np\n# Pearson correlation\nfrom scipy.stats import pearsonr\n\nuser_info = {'Martin Eden': 5,\n            'Pet Sematary': 5,\n            'One Hundred Years of Solitude': 5,\n            'Ham on Rye': 5,\n            'The Grapes of Wrath': 4, \n            \"Cat's Cradle\": 5,\n            'Crime and Punishment': 4,\n            'The Trial': 4}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ratings_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def user_colab(user,others,db_features):\n    # Create dataframe for new user (me)\n    user = pd.DataFrame(columns=['hashtag', 'likes'], data=user.items())\n\n    # Add book_id from books_df\n    new_user = pd.merge(user, db_features, on='hashtag', how='inner')\n    new_user = new_user[['book_id', 'hashtag', 'likes']].sort_values(by='book_id')\n\n    other_users = others[others['book_id'].isin(new_user['book_id'].values)]\n\n    # Sort users by count of most mutual books with me\n    users_mutual_books = other_users.groupby(['user_id'])\n    users_mutual_books = sorted(users_mutual_books, key=lambda x: len(x[1]), reverse=True)\n\n    pearson_corr = {}\n\n    for user_id, features in top_users:\n        # Books should be sorted\n        features = features.sort_values(by='book_id')\n        features_list = features['book_id'].values\n\n        new_user_ratings = new_user[new_user['book_id'].isin(features_list)]['likes'].values \n        user_ratings = features[features['book_id'].isin(features_list)]['rating'].values\n\n        corr = pearsonr(new_user_ratings, user_ratings)\n        pearson_corr[user_id] = corr[0]\n\n    # Get top50 users with the highest similarity indices\n    pearson_df = pd.DataFrame(columns=['user_id', 'similarity_index'], data=pearson_corr.items())\n    pearson_df = pearson_df.sort_values(by='similarity_index', ascending=False)[:50]\n\n    # Get all books for these users and add weighted book's ratings\n    users_rating = pearson_df.merge(ratings_df, on='user_id', how='inner')\n    users_rating['weighted_rating'] = users_rating['rating'] * users_rating['similarity_index']\n\n    # Calculate sum of similarity index and weighted rating for each book\n    grouped_ratings = users_rating.groupby('book_id').sum()[['similarity_index', 'weighted_rating']]\n\n    recommend_tags = pd.DataFrame()\n\n    # Add average recommendation score\n    recommend_tags['avg_reccomend_score'] = grouped_ratings['weighted_rating']/grouped_ratings['similarity_index']\n    recommend_tags['book_id'] = grouped_ratings.index\n    recommend_tags = recommend_books.reset_index(drop=True)\n\n    # Left books with the highest score\n    recommend_tags = recommend_books[(recommend_books['avg_reccomend_score'] == 5)]\n    return recommend_tags\n\nbooks_df.rename(columns={\"title\":\"hashtag\"},inplace=True)\nuser_colab(user_info,ratings_df,books_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2021-09-14T06:34:27.330874Z","iopub.execute_input":"2021-09-14T06:34:27.331272Z","iopub.status.idle":"2021-09-14T06:34:27.33661Z","shell.execute_reply.started":"2021-09-14T06:34:27.331236Z","shell.execute_reply":"2021-09-14T06:34:27.335039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame({'user_0':[0,3,0,5,0,0,4,5,0,2], 'user_1':[0,0,3,2,5,0,4,0,3,0],\n                   'user_2':[3,1,0,3,5,0,0,4,0,0], 'user_3':[4,3,4,2,0,0,0,2,0,0], \n                   'user_4':[2,0,0,0,0,4,4,3,5,0], 'user_5':[1,0,2,4,0,0,4,0,5,0], \n                   'user_6':[2,0,0,3,0,4,3,3,0,0], 'user_7':[0,0,0,3,0,2,4,3,4,0], \n                   'user_8':[5,0,0,0,5,3,0,3,0,4], 'user_9':[1,0,2,0,4,0,4,3,0,0]}, \n                  index=['movie_0','movie_1','movie_2','movie_3','movie_4','movie_5',\n                         'movie_6','movie_7','movie_8','movie_9'])\ndf","metadata":{"execution":{"iopub.status.busy":"2021-09-14T06:34:33.302659Z","iopub.execute_input":"2021-09-14T06:34:33.303181Z","iopub.status.idle":"2021-09-14T06:34:33.341937Z","shell.execute_reply.started":"2021-09-14T06:34:33.303145Z","shell.execute_reply":"2021-09-14T06:34:33.341016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import NearestNeighbors","metadata":{"execution":{"iopub.status.busy":"2021-09-14T06:34:42.501125Z","iopub.execute_input":"2021-09-14T06:34:42.501555Z","iopub.status.idle":"2021-09-14T06:34:42.506591Z","shell.execute_reply.started":"2021-09-14T06:34:42.501513Z","shell.execute_reply":"2021-09-14T06:34:42.505499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn = NearestNeighbors(metric='cosine', algorithm='brute')\nknn.fit(df.values)\ndistances, indices = knn.kneighbors(df.values, n_neighbors=3)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T06:34:47.775667Z","iopub.execute_input":"2021-09-14T06:34:47.776151Z","iopub.status.idle":"2021-09-14T06:34:47.821097Z","shell.execute_reply.started":"2021-09-14T06:34:47.776105Z","shell.execute_reply":"2021-09-14T06:34:47.819522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indices","metadata":{"execution":{"iopub.status.busy":"2021-09-14T06:35:11.249075Z","iopub.execute_input":"2021-09-14T06:35:11.249444Z","iopub.status.idle":"2021-09-14T06:35:11.256945Z","shell.execute_reply.started":"2021-09-14T06:35:11.249413Z","shell.execute_reply":"2021-09-14T06:35:11.255815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"distances","metadata":{"execution":{"iopub.status.busy":"2021-09-14T06:35:18.584912Z","iopub.execute_input":"2021-09-14T06:35:18.585267Z","iopub.status.idle":"2021-09-14T06:35:18.593548Z","shell.execute_reply.started":"2021-09-14T06:35:18.585237Z","shell.execute_reply":"2021-09-14T06:35:18.592045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for title in df.index:\n\n  index_user_likes = df.index.tolist().index(title) # get an index for a movie\n  sim_movies = indices[index_user_likes].tolist() # make list for similar movies\n  movie_distances = distances[index_user_likes].tolist() # the list for distances of similar movies\n  id_movie = sim_movies.index(index_user_likes) # get the position of the movie itself in indices and distances\n\n  print('Similar Movies to '+str(df.index[index_user_likes])+':\\n')\n\n\n  sim_movies.remove(index_user_likes) # remove the movie itself in indices\n  movie_distances.pop(id_movie) # remove the movie itself in distances\n\n  j = 1\n  \n  for i in sim_movies:\n    print(str(j)+': '+str(df.index[i])+', the distance with '+str(title)+': '+str(movie_distances[j-1]))\n    j = j + 1\n      \n  print('\\n')","metadata":{"execution":{"iopub.status.busy":"2021-09-14T06:37:38.509224Z","iopub.execute_input":"2021-09-14T06:37:38.509596Z","iopub.status.idle":"2021-09-14T06:37:38.525079Z","shell.execute_reply.started":"2021-09-14T06:37:38.509564Z","shell.execute_reply":"2021-09-14T06:37:38.524167Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def recommend_movie(title):\n\n  index_user_likes = df.index.tolist().index(title) # get an index for a movie\n  sim_movies = indices[index_user_likes].tolist() # make list for similar movies\n  movie_distances = distances[index_user_likes].tolist() # the list for distances of similar movies\n  id_movie = sim_movies.index(index_user_likes) # get the position of the movie itself in indices and distances\n\n  print('Similar Movies to '+str(df.index[index_user_likes])+': \\n')\n\n  sim_movies.remove(index_user_likes) # remove the movie itself in indices\n  movie_distances.pop(id_movie) # remove the movie itself in distances\n\n  j = 1\n    \n  for i in sim_movies:\n    print(str(j)+': '+str(df.index[i])+', the distance with '+str(title)+': '+str(movie_distances[j-1]))\n    j = j + 1","metadata":{"execution":{"iopub.status.busy":"2021-09-14T06:41:22.477156Z","iopub.execute_input":"2021-09-14T06:41:22.47759Z","iopub.status.idle":"2021-09-14T06:41:22.489001Z","shell.execute_reply.started":"2021-09-14T06:41:22.477549Z","shell.execute_reply":"2021-09-14T06:41:22.487538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recommend_movie('movie_3')","metadata":{"execution":{"iopub.status.busy":"2021-09-14T06:41:31.920381Z","iopub.execute_input":"2021-09-14T06:41:31.920942Z","iopub.status.idle":"2021-09-14T06:41:31.928201Z","shell.execute_reply.started":"2021-09-14T06:41:31.920889Z","shell.execute_reply":"2021-09-14T06:41:31.9271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2021-09-12T11:47:31.624994Z","iopub.execute_input":"2021-09-12T11:47:31.62564Z","iopub.status.idle":"2021-09-12T11:47:31.641338Z","shell.execute_reply.started":"2021-09-12T11:47:31.625584Z","shell.execute_reply":"2021-09-12T11:47:31.640582Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn = NearestNeighbors(metric='cosine', algorithm='brute')\nknn.fit(df.values)\ndistances, indices = knn.kneighbors(df.values, n_neighbors=3)","metadata":{"execution":{"iopub.status.busy":"2021-09-12T11:47:57.488434Z","iopub.execute_input":"2021-09-12T11:47:57.489053Z","iopub.status.idle":"2021-09-12T11:47:57.49636Z","shell.execute_reply.started":"2021-09-12T11:47:57.488995Z","shell.execute_reply":"2021-09-12T11:47:57.495003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index_for_movie = df.index.tolist().index('movie_0') # it returns 0\nsim_movies = indices[index_for_movie].tolist() # make list for similar movies\nmovie_distances = distances[index_for_movie].tolist() # the list for distances of similar movies\nid_movie = sim_movies.index(index_for_movie) # get the position of the movie itself in indices and distances\nsim_movies.remove(index_for_movie) # remove the movie itself in indices\nmovie_distances.pop(id_movie) # remove the movie itself in distances\n\nprint('The Nearest Movies to movie_0:', sim_movies)\nprint('The Distance from movie_0:', movie_distances)","metadata":{"execution":{"iopub.status.busy":"2021-09-12T11:48:30.782802Z","iopub.execute_input":"2021-09-12T11:48:30.783337Z","iopub.status.idle":"2021-09-12T11:48:30.791545Z","shell.execute_reply.started":"2021-09-12T11:48:30.783294Z","shell.execute_reply":"2021-09-12T11:48:30.790665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movie_similarity = [-x+1 for x in movie_distances] # inverse distance \n\npredicted_rating = (movie_similarity[0]*df.iloc[sim_movies[0],7] + movie_similarity[1]*df.iloc[sim_movies[1],7])/sum(movie_similarity)\nprint(predicted_rating)","metadata":{"execution":{"iopub.status.busy":"2021-09-12T11:49:23.62677Z","iopub.execute_input":"2021-09-12T11:49:23.627149Z","iopub.status.idle":"2021-09-12T11:49:23.635892Z","shell.execute_reply.started":"2021-09-12T11:49:23.627114Z","shell.execute_reply":"2021-09-12T11:49:23.63441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find the nearest neighbors using NearestNeighbors(n_neighbors=3)\nnumber_neighbors = 3\nknn = NearestNeighbors(metric='cosine', algorithm='brute')\nknn.fit(df.values)\ndistances, indices = knn.kneighbors(df.values, n_neighbors=number_neighbors)\n\n# copy df\ndf1 = df.copy()\n\n# convert user_name to user_index\nuser_index = df.columns.tolist().index('user_4')\n\n# t: movie_title, m: the row number of t in df\nfor m,t in list(enumerate(df.index)):\n  \n  # find movies without ratings by user_4\n  if df.iloc[m, user_index] == 0:\n    sim_movies = indices[m].tolist()\n    movie_distances = distances[m].tolist()\n    \n    # Generally, this is the case: indices[3] = [3 6 7]. The movie itself is in the first place.\n    # In this case, we take off 3 from the list. Then, indices[3] == [6 7] to have the nearest NEIGHBORS in the list. \n    if m in sim_movies:\n      id_movie = sim_movies.index(m)\n      sim_movies.remove(m)\n      movie_distances.pop(id_movie) \n\n    # However, if the percentage of ratings in the dataset is very low, there are too many 0s in the dataset. \n    # Some movies have all 0 ratings and the movies with all 0s are considered the same movies by NearestNeighbors(). \n    # Then,even the movie itself cannot be included in the indices. \n    # For example, indices[3] = [2 4 7] is possible if movie_2, movie_3, movie_4, and movie_7 have all 0s for their ratings.\n    # In that case, we take off the farthest movie in the list. Therefore, 7 is taken off from the list, then indices[3] == [2 4].\n    else:\n      sim_movies = sim_movies[:number_neighbors-1]\n      movie_distances = movie_distances[:number_neighbors-1]\n        \n    # movie_similarty = 1 - movie_distance    \n    movie_similarity = [1-x for x in movie_distances]\n    movie_similarity_copy = movie_similarity.copy()\n    nominator = 0\n\n    # for each similar movie\n    for s in range(0, len(movie_similarity)):\n      \n      # check if the rating of a similar movie is zero\n      if df.iloc[sim_movies[s], user_index] == 0:\n\n        # if the rating is zero, ignore the rating and the similarity in calculating the predicted rating\n        if len(movie_similarity_copy) == (number_neighbors - 1):\n          movie_similarity_copy.pop(s)\n          \n        else:\n          movie_similarity_copy.pop(s-(len(movie_similarity)-len(movie_similarity_copy)))\n\n      # if the rating is not zero, use the rating and similarity in the calculation\n      else:\n        nominator = nominator + movie_similarity[s]*df.iloc[sim_movies[s],user_index]\n\n    # check if the number of the ratings with non-zero is positive\n    if len(movie_similarity_copy) > 0:\n      \n      # check if the sum of the ratings of the similar movies is positive.\n      if sum(movie_similarity_copy) > 0:\n        predicted_r = nominator/sum(movie_similarity_copy)\n\n      # Even if there are some movies for which the ratings are positive, some movies have zero similarity even though they are selected as similar movies.\n      # in this case, the predicted rating becomes zero as well  \n      else:\n        predicted_r = 0\n\n    # if all the ratings of the similar movies are zero, then predicted rating should be zero\n    else:\n      predicted_r = 0\n\n  # place the predicted rating into the copy of the original dataset\n    df1.iloc[m,user_index] = predicted_r","metadata":{"execution":{"iopub.status.busy":"2021-09-12T11:56:28.497552Z","iopub.execute_input":"2021-09-12T11:56:28.497909Z","iopub.status.idle":"2021-09-12T11:56:28.523068Z","shell.execute_reply.started":"2021-09-12T11:56:28.497879Z","shell.execute_reply":"2021-09-12T11:56:28.52191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def recommend_movies(user, num_recommended_movies):\n\n  print('The list of the Movies {} Has Watched \\n'.format(user))\n\n  for m in df[df[user] > 0][user].index.tolist():\n    print(m)\n  \n  print('\\n')\n\n  recommended_movies = []\n\n  for m in df[df[user] == 0].index.tolist():\n\n    index_df = df.index.tolist().index(m)\n    predicted_rating = df1.iloc[index_df, df1.columns.tolist().index(user)]\n    recommended_movies.append((m, predicted_rating))\n\n  sorted_rm = sorted(recommended_movies, key=lambda x:x[1], reverse=True)\n  \n  print('The list of the Recommended Movies \\n')\n  rank = 1\n  for recommended_movie in sorted_rm[:num_recommended_movies]:\n    \n    print('{}: {} - predicted rating:{}'.format(rank, recommended_movie[0], recommended_movie[1]))\n    rank = rank + 1","metadata":{"execution":{"iopub.status.busy":"2021-09-12T11:57:16.897802Z","iopub.execute_input":"2021-09-12T11:57:16.898344Z","iopub.status.idle":"2021-09-12T11:57:16.908974Z","shell.execute_reply.started":"2021-09-12T11:57:16.898308Z","shell.execute_reply":"2021-09-12T11:57:16.90802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recommend_movies('user_4',5)","metadata":{"execution":{"iopub.status.busy":"2021-09-12T11:58:15.371284Z","iopub.execute_input":"2021-09-12T11:58:15.371832Z","iopub.status.idle":"2021-09-12T11:58:15.400072Z","shell.execute_reply.started":"2021-09-12T11:58:15.371795Z","shell.execute_reply":"2021-09-12T11:58:15.398964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = df.copy()\n\ndef movie_recommender(user, num_neighbors, num_recommendation):\n  \n  number_neighbors = num_neighbors\n\n  knn = NearestNeighbors(metric='cosine', algorithm='brute')\n  knn.fit(df.values)\n  distances, indices = knn.kneighbors(df.values, n_neighbors=number_neighbors)\n\n  user_index = df.columns.tolist().index(user)\n\n  for m,t in list(enumerate(df.index)):\n    if df.iloc[m, user_index] == 0:\n      sim_movies = indices[m].tolist()\n      movie_distances = distances[m].tolist()\n    \n      if m in sim_movies:\n        id_movie = sim_movies.index(m)\n        sim_movies.remove(m)\n        movie_distances.pop(id_movie) \n\n      else:\n        sim_movies = sim_movies[:num_neighbors-1]\n        movie_distances = movie_distances[:num_neighbors-1]\n           \n      movie_similarity = [1-x for x in movie_distances]\n      movie_similarity_copy = movie_similarity.copy()\n      nominator = 0\n\n      for s in range(0, len(movie_similarity)):\n        if df.iloc[sim_movies[s], user_index] == 0:\n          if len(movie_similarity_copy) == (number_neighbors - 1):\n            movie_similarity_copy.pop(s)\n          \n          else:\n            movie_similarity_copy.pop(s-(len(movie_similarity)-len(movie_similarity_copy)))\n            \n        else:\n          nominator = nominator + movie_similarity[s]*df.iloc[sim_movies[s],user_index]\n          \n      if len(movie_similarity_copy) > 0:\n        if sum(movie_similarity_copy) > 0:\n          predicted_r = nominator/sum(movie_similarity_copy)\n        \n        else:\n          predicted_r = 0\n\n      else:\n        predicted_r = 0\n        \n      df1.iloc[m,user_index] = predicted_r\n  recommend_movies(user,num_recommendation)","metadata":{"execution":{"iopub.status.busy":"2021-09-12T12:00:35.728187Z","iopub.execute_input":"2021-09-12T12:00:35.728642Z","iopub.status.idle":"2021-09-12T12:00:35.746791Z","shell.execute_reply.started":"2021-09-12T12:00:35.728551Z","shell.execute_reply":"2021-09-12T12:00:35.745626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movie_recommender('user_4', 4, 5)","metadata":{"execution":{"iopub.status.busy":"2021-09-12T12:01:37.237852Z","iopub.execute_input":"2021-09-12T12:01:37.238253Z","iopub.status.idle":"2021-09-12T12:01:37.25484Z","shell.execute_reply.started":"2021-09-12T12:01:37.238217Z","shell.execute_reply":"2021-09-12T12:01:37.253412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"https://github.com/yjeong5126/movie_recommender","metadata":{}},{"cell_type":"code","source":"ratings = pd.read_csv('ratings.csv', usecols=['userId','movieId','rating'])\nmovies = pd.read_csv('https://github.com/yjeong5126/movie_recommender/blob/master/item_based_collaborative_filtering/movies.csv', \n                     usecols=['movieId','title'])\nratings2 = pd.merge(ratings, movies, how='inner', on='movieId')","metadata":{},"execution_count":null,"outputs":[]}]}